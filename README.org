* A Conversational Read Eval Print Loop for Books&Articles
**TODO gif or youtube example

* TO RUN
****  - TODO gifs or youtube playlist here
****  - if windows then install windows subsystem for linux 
****  - https://nixos.org/download.html (select appropriate operating system from siderbar)
****  - git clone https://github.com/NotBrianZach/gptbook2quiz.git
****  - cd gptbook2quiz
****  - nix-shell (flake is work in progress)
****  - make a pull request implementing pretty much all the features this project currently needs to be a nice user experience
**** 	- npm install
****  - ./book2quiz.sh $OPEN_API_KEY path_2_ur_pdf_here.pdf
****  - open an issue detailing why doesnt work

** how to read this
*** numbers e.g. 1. indicate steps in the event loop, letters are steps that happen in a given workflow
*** a.1 -> step a happens before step 1, but after step 0
*** 1.a -> step 1 happens before step a
*** 1.b -> step 1 happens before step a, step b happens after step a
*** 1-a -> step 1 happens concurrently/asynchronously to step a

** Giving gpt3 Short&Long term memory
*** 0. read the title, print&query user to verify, if not query user for title
*** 1. if can find table of contents then synopsize&user validates, else query user for synopsis
*** 2. n= user input pageNumber (default 0), m=user input chunkSize (default 2), rollingSummary=empty string

***TODO steps 0-2 can also be done from information stored in readingList

*** 3. feed gpt3 pages[n:n+m], prepending prependContext&synopsis&title&rollingSummary, appending appendContext, summarize pages[n:n+m]
*** 4. query gpt3 w/synopsis+summary of pages[n:n+m] to generate a new rollingSummary
*** 5. while pageNumber < bookLength, set n=n+m, go back to 3.
*** 6. onExit callback function 

** Quiz Mode: Start with book pdf, then
**** 1.a. generate quiz,
**** 2.a. display summary of pages[n:n+m] and quiz to the user, record user answer to quiz
**** 2.b. (optional, default quiz&answer) gpt attempts to answer the quiz prints answers, R for user reply to answers
**** 6.a record a log of all the summaries and quizzes

** Query Mode: 
**** 1.a query user for question, 
**** 1.b answer user question, query user C=continue to next page,Q=ask another question,R=query gpt3 w/user reply on question answer
**** 6.a record a log of all questions&answers

** Rewrite Mode: 

**** 1. ask user for character (e.g. aristotle)
**** 2. read pages, rewrite in characters voice

* Narrate Submode: 
*** todo use elevenlabs api to generate voice

* VoiceDiction Submode: 
*** todo use ?talon? to allow voice input?

* Reading List Utility (readList.sh)

store path to pdf and relevant executable to read it

backup&rotate logs

switch between query or quiz mode without losing page context using logs

* Design decisions

pdf-extract introduces a bunch of binary dependencies relative to
alternative libraries but we want those because they enable ocr on the subset of pdfs
that don't cleanly delineate text

* Inspiration
i had previously kept a reading list with commands like

"""

# 0-
ebook-viewer ~/media/books/TheDividedSelf2010.epub --open-at 59

# 0-
xpdf ~/media/books/tcp_ip_networkadministration_3rdedition.pdf 50 -z 200

xpdf ~/media/books/LinuxProgrammingInterface2010.pdf

"""

in a file in my /home/$user/media directory so i could read books from command line and record current position

i had also been looking for technically inclined book club without luck

thought had been bubbling in my head that I wanted to read books alongside gpt3,

i had previously spent several years trying to make multi player choose your own adventure novels a thing (and maybe still plan to?)

i really thought, and think, that technology has vast potential to create new narrative structures

then i saw this reddit post

https://www.reddit.com/r/singularity/comments/11ho23y/first_post_in_reddit_mistakely_used_a_text_post/

and a within a couple minutes, after some good ole reddit arguing, i started writing this

actually, a final thought, about fundamental models of computation

the taxonomy of computation looks like this

finite state machines -> context free grammars -> turing machines

traditional narratives are particularly simple finite state machines at the level of pages

most choose your own adventure novels are also finite state machines, though they have a bit more structure since they are not purely sequential

the way I wanted to implement multiplayer choose your own adventure novels,

i believe they would have been more akin to a push down automata, or context free grammar,

since the story would maintain a list of invalidated edges (which could also be thought of as a unique class of "intermediate" node that dont branch),

and transitions between nodes could change the choices available to other players

i think there is a similar analogy going on here.

reddit user SignificanceMassive3's diagram displays a "context free" or "pushdown" large language model

which, much like a regular expression is suitable for parsing text, is suitable for the task of reading along with longer form text 
