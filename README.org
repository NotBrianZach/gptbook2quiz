* this repo has moved https://github.com/NotBrianZach/bzaBook2AQuiz eventually will move  https://github.com/NotBrianZach/bza
**TODO gif or youtube example

* TO RUN
****  - TODO gifs or youtube playlist here
****  - if windows then install windows subsystem for linux 
****  - https://nixos.org/download.html (select appropriate operating system from siderbar)
****  - git clone https://github.com/NotBrianZach/bzabook2aquiz.git
****  - cd bzabook2aquiz
****  - nix-shell (flake is work in progress) todo check if mac and use darwin nixpkgs
****  - make a pull request implementing pretty much all the features this project currently needs to be a nice user experience
**** 	- npm install
****  - ./book2quiz.sh $OPEN_API_KEY path_2_ur_pdf_here.pdf
****  - get $OPEN_API_KEY key here if u dont have https://platform.openai.com/account/api-keys
****  - open an issue detailing why doesnt work

** how to read this
**** numbers are steps in the event loop, letters are steps in a given workflow (which modifies event loop)
**** a.1 -> step a happens before step 1, but after step 0
**** 1.a -> step 1 happens before step a
**** 1.b -> step 1 happens before step a, step b happens after step a
**** 1-a -> step 1 happens concurrently/asynchronously to step a

** Giving gpt3 Short&Long term memory (Event Loop)
*** 1. IF EXISTS, load title&synopsis&rollingSummary from readingList.json ELSE try to grab title, query user C=confirm, string=user inputs title, query user for page range of table of contents if input=([0-9]*-[0-9]*) try to synopsize and validate with user, else ask user input synopsis, rollingSummary=empty string
*** 2. IF EXISTS, load pageNumber, chunkSize from reagingList.json, ELSE pageNumber=commandline param (default 0), chunkSize=commandline param  (default 2)
*** 3. feed gpt3 pages[pageNumber:pageNumber+chunkSize], prepending beforeContext&synopsis&title&rollingSummary, appending afterContext, summarize pages[n:n+m]
*** 4. query gpt3 w/synopsis+summary of pages[pageNumber:pageNumber+chunkSize] to generate a new rollingSummary
*** 5. while pageNumber < bookLength, set pageNumber=pageNumber+chunkSize, go back to 3.
*** 6. onExit callback function 

** Quiz Mode: Start with book pdf, then
**** 1.a. generate quiz,
**** 2.a. display summary of pages[pageNumber:pageNumber+chunkSize] and quiz to the user, record user answer to quiz
**** 2.b. (optional, default quiz&answer) gpt attempts to answer the quiz prints answers, R for user reply to answers
**** 6.a record a log of all the summaries and quizzes

** Quiz&Answer Mode: Start with book pdf, then
**** 1.a. generate quiz,
**** 2.a. display summary of pages[pageNumber:pageNumber+chunkSize] and quiz to the user, record user answer to quiz
**** 2.b. gpt attempts to answer the quiz prints answers,
***** query user-> R for user reply to answers, on other input continue
**** 6.a record a log of all the summaries and quizzes

** Query Mode: 
**** 1.a query user for question, 
**** 1.b gpt3 answer user query,  
***** query user
****** C=continue to next page,
****** Q=ask another question, repeat 1.b
****** r=query gpt3 w/user reply on question answer,
****** A= append next query input to gpt query at the start of each chunk
****** B= prepend next query input to gpt query at the start of each chunk
****** e.g. tell a joke about the following 
**** 6.a record a log of all questions&answers


** Rewrite Mode: 

**** 1.a ask user for character (e.g. socrates) (any string will be accepted)
**** 2.a read pages, rewrite in characters voice

** Narrate Submode: 
*** todo use https://github.com/coqui-ai/TTS to generate voice
*** to narrate gpt response

** VoiceDiction Submode: 
*** todo use ?talon? to allow voice input?

* Reading List Utility (readList.sh)

store path to pdf and relevant executable to read it

backup&rotate logs

switch between query or quiz mode without losing page context using logs

* Design decisions

pdf-extract introduces a bunch of binary dependencies relative to
alternative libraries but we want those because they enable ocr on the subset of pdfs
that don't cleanly delineate text

* Naming

bza are my initials.

also naive pronounciation sounds kind of like pizza, which is typically
sliced into pizza just like we are chunking up books.

and bza is a short three letter word which is not too overloaded and can be invoked easily on the command line.

finally, book starts with B, quiz ends with Z and a is a.

makes total sense.

just bza it!

* Inspiration

i had previously kept a reading list with commands like

"""

# 0-
ebook-viewer ~/media/books/TheDividedSelf2010.epub --open-at 59

# 0-
xpdf ~/media/books/tcp_ip_networkadministration_3rdedition.pdf 50 -z 200

xpdf ~/media/books/LinuxProgrammingInterface2010.pdf

"""

in a file in my /home/$user/media directory so i could read books from command line and record current position

i had also been looking for technically inclined book club without luck

thought had been bubbling in my head that I wanted to read books alongside gpt3,

i had previously spent several years trying to make multi player choose your own adventure novels a thing (and maybe still plan to?)

i really thought, and think, as a massive wordcel, that computers have a vast potential to create new narrative structures

then i saw this reddit post

https://www.reddit.com/r/singularity/comments/11ho23y/first_post_in_reddit_mistakely_used_a_text_post/

and a within a couple minutes, after some good ole reddit arguing, i started writing this

** Pushdown Large Language Models

actually, a final thought, about fundamental models of computation

the taxonomy of computation looks like this

finite state machines -> context free grammars -> turing machines

traditional narratives are particularly simple finite state machines at the level of pages

most choose your own adventure novels are also finite state machines, though they have a bit more structure since they are not purely sequential

the way I wanted to implement multiplayer choose your own adventure novels,

i believe they would have been more akin to a push down automata, or context free grammar,

since the story would maintain a list of invalidated edges (which could also be thought of as a unique class of "intermediate" node that dont branch),

and transitions between nodes could change the choices available to other players

i think there is a similar analogy going on here.

reddit user SignificanceMassive3's diagram displays a "context free" or "pushdown" large language model

which, much like a regular expression is suitable for parsing text, is suitable for the task of reading along with longer form text 
